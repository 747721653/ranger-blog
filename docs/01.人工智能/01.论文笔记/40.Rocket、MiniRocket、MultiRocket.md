---
title: Rocket、MiniRocket、MultiRocket
date: 2023-03-20 14:02:05
permalink: /pages/45b6e8/
categories:
  - 人工智能
  - 论文笔记
tags:
  - 
author: 
  name: yangzhixuan
  link: https://github.com/747721653
---
## Rocket
### 摘要
大多数时间序列分类方法都具有很高的计算复杂度，即使对于较小的数据集也需要大量的训练时间，并且对于较大的数据集也难以处理。
此外，许多现有的方法都专注于单一类型的特征，如形状或频率。基于卷积神经网络对时间序列分类的最近成功，
我们证明了使用随机卷积核的简单线性分类器可以实现最先进的精度，而计算成本仅为现有方法的一小部分。
使用这种方法，可以在不到2小时内在UCR档案中的所有85个“bake off”数据集上训练和测试分类器，并且可以在大约1小时内在超过100万个时间序列的大型数据集上训练分类器。

---------------------------------------

### 方法
主要思想：使用多个随机卷积核对时间序列进行转换，并使用转换后的特征来训练线性分类器

#### 随机卷积核
**为什么？**

在UCR这种小数据集上使用卷积神经网络的效果并不是很好，因为卷积神经网络需要大量的数据进行训练，随机卷积核对这种小数据集可能会拥有更好的效果

**Rocket与典型卷积神经网络中使用的卷积层，以及与之前使用卷积核（包括随机卷积核）的时间序列的工作有以下四个不同：**
1. Rocket使用了大量的内核。由于只有一层核，并且不学习核的权重，计算卷积的成本很低，并且可以使用大量的核，而计算成本相对较低。
2. Rocket使用了大量不同的内核。与典型的卷积神经网络相反，在典型的卷积神经网络中，一组内核共享相同的大小、膨胀和填充，对于Rocket来说，每个内核都有随机的长度、膨胀和填充，以及随机的权重和偏差。
3. Rocket使用了内核膨胀。与卷积神经网络中膨胀的典型使用相反，在卷积神经网络中，扩张随着深度呈指数级增长，我们对每个内核随机采样膨胀，产生各种各样的内核膨胀，捕捉不同频率和尺度的模式，这对方法的性能至关重要。
4. 除了对生成的特征使用最大池化，Rocket还使用了正值的比例(或ppv)。这使分类器能够在时间序列中衡量给定模式的流行程度。这是Rocket架构中最关键的一个元素，对其卓越的精度至关重要。

**随机卷积核的特点：**
* 长度：随机卷积核的长度以相同的概率从{7,9,11}中随机选择
* 权重：随机卷积核的每个权重$\forall w\in\textbf{W}$从正态分布$w\sim\mathcal{N}(0,1)$中采用，之后减去整体的均值，即$\omega=\mathbf{W}-\overline{{\mathbf{W}}}$，这样，使得大多数权重相对较小，当总体具有更大的幅度
* 偏置：偏置从均匀分布$b\sim U\left(-1,1\right)$中采样，这样做的作用是，由于在计算ppv的时候，只有特征中的正值才会产生影响，这样对两个相似的卷积核，在拥有不同偏置的情况下，可以通过将特征中的值移到0以上或0以下，从而突出特征图中的不同方面
* 膨胀：膨胀从指数尺度$d=\left\lfloor2^{x}\right\rfloor,x\sim U\left(0,A\right)$进行采样，这里$A=\log_{2}\frac{l_{\text{input}}-1}{l_{\text{kernel}}-1}$，保证了膨胀之后的卷积核的有效长度不超过输入时间序列的长度，膨胀使得其他相似的卷积核能以不同的频率和规模匹配相似的模式
* 填充（padding）：在生成卷积核时，将以相同概率随机决定是否对卷积核进行填充，若使用了填充，则在使用卷积核的时候，在每个时间序列的开始和结束处都会附加一个零填充量，以此使得时间序列中的每个点都能被卷积核的中间元素匹配（其实是排除膨胀的影响，因为膨胀之后卷积核的外围全是0，这样给时间序列加上合适的0填充就能使得时间序列的两侧被原本的卷积核所匹配），填充的长度为$\left(\left(l_{k e m e l}-1\right)\times d\right)/2$。在没有填充的情况下，卷积核就无法匹配时间序列的两端，而集中于时间序列中心区域的模式。

**其他细节：**
在进行卷积计算时，步长永远为1，同时不使用非线性激活函数，并且输入的时间序列经过归一化，即处理为均值为0，方差为1的形式，卷积核的个数为超参数，默认值为10000

-------------------------------------

#### 时间序列变换
每个卷积核应用于每个输入时间序列，产生一个特征映射，卷积运算涉及卷积核和输入时间序列之间的滑动点击，从$X$中的位置$i$开始，对给定时间序列$X$应用具有膨胀$d$和偏差$b$的核$ω$的结果如下：
:::center
![image](https://cdn.staticaly.com/gh/747721653/image-store@master/paper/image.7hswe3gd1cw0.jpg)
:::
Rocket从每个特征映射中计算两个聚合特征，即对于每个时间序列，每个卷积核会生成两个实数作为特征，分别是最大值（最大池化）以及ppv（$p p v(\mathbf{Z})=\frac{1}{n}\sum_{i=0}^{n-1}[z_{i}>0]$，其中，$Z$是卷积运算的输出）

也就是说，对于k个内核，Rocket会在每个时间序列中生成2k个特征；对于10000个内核，Rocket会生成20000个特征，对于较小的数据集（例如UCR档案上的所有数据集），特征的数量可能比数据集中的实例数量或每个时间序列中的元素数量大得多。

----------------------------------
#### 分类器
将转换后的特征用于训练线性分类器，当数据集的长度小于特征的数量（即默认情况下，少于20000个训练样本）时，使用岭回归分类器（ridge regression classifier），否则使用一般的逻辑回归。

逻辑回归Rocket可以与逻辑回归和随机梯度下降一起使用。这特别适合于非常大的数据集，因为它提供了固定内存成本的快速训练(由每个小批的大小固定)。转换可以在每个小批上执行，也可以在数据集的较大部分上执行，然后将其进一步划分为小批进行训练。

然而，对于UCR档案中的所有数据集，我们使用岭回归分类器，其中岭回归模型以“one versus rest”的方式为每个类训练，并具有L2正则化。

当特征的数量显著大于训练示例的数量时，正则化是至关重要的，它允许线性模型的优化，并防止迭代优化中的病态行为，例如，对于逻辑回归。岭回归分类器可以利用泛化交叉验证快速确定适当的正则化参数。我们发现，对于较小的数据集，岭回归分类器在实践中明显快于逻辑回归，同时仍能实现较高的分类精度。我们发现，对于较小的数据集，优化逻辑回归的多个超参数(小批量大小、学习率、正则化等)以达到与岭回归分类器相同的分类精度明显更具挑战性和耗时。

---------------------------------------

### 限制
Rocket的一个限制是，为了达到最高的分类精度，需要大量的卷积核，这反过来又限制了分类器的选择，即那些对大量特征有效的分类器(包括岭回归分类器和逻辑回归)。另一个限制是，在使用固定的随机卷积核时，对于非常大的数据集，学习可能会在某个时候“饱和”。我们期望更多典型的卷积神经网络架构与学习内核，如InceptionTime，在非常大的数据集上实现更高的精度，尽管计算成本要高得多。然而，Rocket至少可以用于非常大的数据集，而许多现有的时间序列分类方法都不能，并且我们注意到，卫星图像时间序列数据集的准确性似乎只在大约50万个训练示例之后才趋于稳定(参见第4.2节)。Rocket目前只配置为使用单变量时间序列。Rocket的扩展到多元时间序列和应用到非常大的数据集是未来工作的重点。

------------------------------------------------
## MiniRocket
### 摘要
Rocket通过使用随机卷积核转换输入时间序列，并使用转换后的特征来训练线性分类器，从而实现了最先进的时间序列分类精度，而计算成本仅为大多数现有方法的一小部分。我们重新设计了一种新的方法，迷你火箭。
在更大的数据集上，MiniRocket的速度比Rocket快75倍，而且几乎是确定的(可选的是完全确定的)，同时保持本质上相同的精度。使用这种方法，可以在10分钟内在UCR档案的所有109个数据集上训练和测试分类器，达到最先进的精度。
MiniRocket比任何其他具有相当精度的方法(包括Rocket)都要快得多，并且比任何其他计算成本类似的方法都要准确得多。



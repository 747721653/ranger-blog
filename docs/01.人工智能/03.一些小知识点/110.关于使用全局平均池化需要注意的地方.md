## 踩的坑
之前在做实验的时候，发现网络训练不动，经过调试发现输入的数据在过了一层全局平均池化之后都变为了接近0的值，起初以为是平均池化的锅，找了半天没找到问题所在。

后来仔细检查网络结构时发现，我在使用全局平均池化前有一个Transformer的编码器层，无意之间又看了看，发现最后的输出要做一个layernorm，猛然惊醒，layernorm
会将一个特征里的数据转换为均值为0，方差为1的形式，均值为0。。。。。。。。这不就是为什么后面的全局平均池化计算结果为0的原因吗，困扰了许久的bug终于解决了。。。。

## 吸取的教训
以后在使用全局平均池化之前一定要注意是不是使用了归一化操作，仔细检查归一化作用的维度以及平均池化作用的维度是否一致！！！
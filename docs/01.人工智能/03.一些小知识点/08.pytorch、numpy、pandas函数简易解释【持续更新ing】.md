---
title: pytorch、numpy、pandas函数简易解释【持续更新ing】
date: 2023-02-24 14:29:00
permalink: /pages/52b4a3/
categories:
  - 人工智能
  - 一些小知识点
tags:
  - 
author: 
  name: yangzhixuan
  link: https://github.com/747721653
---
## pytorch
### torch.triu()
返回一个上三角矩阵，常见于mask操作

函数原型：
```python
def triu(input: Tensor, diagonal: _int=0, *, out: Optional[Tensor]=None) -> Tensor: ...
```
示例：[https://blog.csdn.net/weixin_39574469/article/details/118195536](https://blog.csdn.net/weixin_39574469/article/details/118195536)

### .transpose()
将tensor的维度进行交换

示例：[https://blog.csdn.net/a250225/article/details/102636425](https://blog.csdn.net/a250225/article/details/102636425)

### model.eval()
在对模型进行评估时，需要使用这个函数

它的作用是不启用 Batch Normalization 和 Dropout

如果模型中有BN层(Batch Normalization）和Dropout，在测试时添加model.eval()。
model.eval()是保证BN层能够用全部训练数据的均值和方差，即测试过程中要保证BN层的均值和方差不变。
对于Dropout，model.eval()是利用到了所有网络连接，即不进行随机舍弃神经元。

教程：[https://blog.csdn.net/lgzlgz3102/article/details/115987271](https://blog.csdn.net/lgzlgz3102/article/details/115987271)

### torch.linspace()
函数原型：
```python
torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
```
作用为返回一个一维的tensor，包含从start到end的等距的steps个数据点

示例：[https://blog.csdn.net/weixin_43255962/article/details/84347726](https://blog.csdn.net/weixin_43255962/article/details/84347726)

### torch.Tensor.permute()
将tensor的维度换位

参数：`dims (int …*)` 换位顺序

例：
```python
>>> x = torch.randn(2, 3, 5) 
>>> x.size() 
torch.Size([2, 3, 5]) 
>>> x.permute(2, 0, 1).size() 
torch.Size([5, 2, 3])
```
详解：[https://blog.csdn.net/qq_43489708/article/details/125154452](https://blog.csdn.net/qq_43489708/article/details/125154452)

### torchvision.transforms.RandomResizedCrop()
```python
def __init__(self, size, scale=(0.08, 1.0), ratio=(3.0 / 4.0, 4.0 / 3.0), interpolation=InterpolationMode.BILINEAR):
```
将给定图像随机裁剪成不同的大小和宽高比，然后缩放所裁剪得到的图像为制定的大小（即先随机采集，然后对裁剪得到的图像缩放为统一大小）

示例：
```python
img = Image.open("./demo.jpg")
print("原图大小：",img.size)
data1 = transforms.RandomResizedCrop(224)(img)
print("随机裁剪后的大小:",data1.size)
data2 = transforms.RandomResizedCrop(224)(img)
data3 = transforms.RandomResizedCrop(224)(img)

plt.subplot(2,2,1),plt.imshow(img),plt.title("原图")
plt.subplot(2,2,2),plt.imshow(data1),plt.title("转换后的图1")
plt.subplot(2,2,3),plt.imshow(data2),plt.title("转换后的图2")
plt.subplot(2,2,4),plt.imshow(data3),plt.title("转换后的图3")
plt.show()
```
效果：
:::center
![image](https://cdn.statically.io/gh/747721653/picx-images-hosting@master/tips/image.6lcq0r6qkso0.jpg)
:::

### torchvision.transforms.RandomHorizontalFlip()
以给定的概率随机水平旋转给定的PIL的图像，默认为0.5

示例：
```python
img = Image.open("./demo.jpg")
img1 = transforms.RandomHorizontalFlip()(img)
img2 = transforms.RandomHorizontalFlip()(img)
img3 = transforms.RandomHorizontalFlip()(img)

plt.subplot(2,2,1),plt.imshow(img),plt.title("原图")
plt.subplot(2,2,2), plt.imshow(img1), plt.title("变换后的图1")
plt.subplot(2,2,3), plt.imshow(img2), plt.title("变换后的图2")
plt.subplot(2,2,4), plt.imshow(img3), plt.title("变换后的图3")
plt.show()
```
效果：
:::center
![image](https://cdn.statically.io/gh/747721653/picx-images-hosting@master/tips/image.77teocbgwgk0.jpg)
:::


### torch.max()
返回输入的tensor中所有维度的最大值
```python
torch.max(input, dim, keepdim=False, *, out=None)
```
一维情况：
```python
>>> a = torch.randn(1, 3)
>>> a
tensor([[ 0.6763,  0.7445, -2.2369]])
>>> torch.max(a)
tensor(0.7445)
```

多维情况：
```python
>>> a = torch.randn(4, 4)
>>> a
tensor([[-1.2360, -0.2942, -0.1222,  0.8475],
        [ 1.1949, -1.1127, -2.2379, -0.6702],
        [ 1.5717, -0.9207,  0.1297, -1.8768],
        [-0.6172,  1.0036, -0.6060, -0.2432]])
>>> torch.max(a, 1)
torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1]))
```
多维情况时维度指的是要比较的维度，会返回这个维度所有tensor的大小，如将上述例子中的dim改为0，则是对0维里四个长度为4的tensor进行比较，返回4列的最大值，并放回从0开始的索引

### torch.eq()
比较两个tensor的相等情况，若相同位置上的值相同则在这个位置上返回True

函数原型：
```python
torch.eq(input, other, *, out=None) → Tensor
```
例子：
```python
>>> torch.eq(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))
tensor([[ True, False],
        [False, True]])
```
可以配合tensor.sum()快速计算True的个数从而计算正确率等信息

### torch.view()
将tensor的形状改变，与reshape的作用相似，先将所有元素按照维度平铺为一维，在根据目标维度平铺回去

例：
```python
>>> import torch
>>> t1 = torch.tensor([1,2,3,4,5,6])
>>> result = tt1.view(3,2)
>>> result
tensor([[1, 2],
        [3, 4],
        [5, 6]])
```
参数为-1时会自动计算维度
```python
>>> t2 = torch.tensor([1,2,3],[4,5,6],[7,8,9])
>>> result = t2.view(-1)
tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])
```

### torch.split()
```python
torch.split(input, split_size_or_sections, dim = 0)
```
函数会将输入input沿着指定维度dim分割成特点数量的张量块，并返回元素为张量块的元素。
简单来说，可以将 torch.split 函数看成是 torch.chunk 函数的进阶版，因为 torch.split 不仅能够指定块数均匀分割（torch.chunk 只能指定块数均匀分割），而且能够指定分割每一块的长度。
参数解释如下：
* tensor(Tensor)：待分割的输入张量，此处的tensor参数和 torch.chunk函数中的input参数类似，只需要注意使用关键字参数时候的参数名
* split_size_or_sections（int）or（list(int)）参数：
  * 指定为int时，和`torch.chunk(input, chunks, dim = 0)`函数中的 chunks 参数功能一样；
  * 指定为 list(int) 时，list 中的每一个整数元素代表分割的块数，而每个块的长度由对应的整型元素决定；
* dim（int）：进行分割的维度


### torch.chunk()
```python
torch.chunk(input, chunks, dim=0) → List of Tensors
```
参数：
* input(Tensor): 要分割的tensor
* chunks(int): 分割的块数
* dim(int): 要分割的维度


### torch.ones_like()和torch.zeros_like()
给定张量，生成与其形状相同的全1张量或全0张量
```python
def ones_like(self: Tensor, *, dtype: _dtype=None, layout: layout=strided, device: Union[_device, str, None]=None, requires_grad:_bool=False) -> Tensor: ...

def zeros_like(self: Tensor, *, dtype: _dtype=None, layout: layout=strided, device: Union[_device, str, None]=None, requires_grad:_bool=False) -> Tensor: ...
```

### torch.tril()
返回给定张量的下三角矩阵
```python
torch.tril(input, diagonal=0, *, out=None) → Tensor
```
参数：
* input(Tensor): 输入张量
* diagonal(int): 要考虑的对角线

当diagonal为0时表示保留主对角线的所有元素

当diagonal为正数时表示保留主对角线右上侧对应值的元素

当diagonal为负数时表示排除主对角线左下侧对应值的元素

例：
```python
>>> import torch
>>> a = torch.randn(3, 4)
>>> import torch
>>> a = torch.randn(3, 3)
>>> a
tensor([[ 0.4925,  1.0023, -0.5190],
        [ 0.0464, -1.3224, -0.0238],
        [-0.1801, -0.6056,  1.0795]])
>>> torch.tril(a)
tensor([[ 0.4925,  0.0000,  0.0000],
        [ 0.0464, -1.3224,  0.0000],
        [-0.1801, -0.6056,  1.0795]])
>>> b = torch.randn(4, 6)
>>> b
tensor([[-0.7886, -0.2559, -0.9161,  0.2353,  0.4033, -0.0633],
        [-1.1292, -0.3209, -0.3307,  2.0719,  0.9238, -1.8576],
        [-1.1988, -1.0355, -1.2745, -1.7479,  0.3736, -0.7210],
        [-0.3380,  1.7570, -1.6608, -0.4785,  0.2950, -1.2821]])
>>> torch.tril(b)
tensor([[-0.7886,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [-1.1292, -0.3209,  0.0000,  0.0000,  0.0000,  0.0000],
        [-1.1988, -1.0355, -1.2745,  0.0000,  0.0000,  0.0000],
        [-0.3380,  1.7570, -1.6608, -0.4785,  0.0000,  0.0000]])
>>> torch.tril(b, diagonal=1)
tensor([[-0.7886, -0.2559,  0.0000,  0.0000,  0.0000,  0.0000],
        [-1.1292, -0.3209, -0.3307,  0.0000,  0.0000,  0.0000],
        [-1.1988, -1.0355, -1.2745, -1.7479,  0.0000,  0.0000],
        [-0.3380,  1.7570, -1.6608, -0.4785,  0.2950,  0.0000]])
>>> torch.tril(b, diagonal=-1)
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [-1.1292,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [-1.1988, -1.0355,  0.0000,  0.0000,  0.0000,  0.0000],
        [-0.3380,  1.7570, -1.6608,  0.0000,  0.0000,  0.0000]])
>>> torch.tril(b, diagonal=2)
tensor([[-0.7886, -0.2559, -0.9161,  0.0000,  0.0000,  0.0000],
        [-1.1292, -0.3209, -0.3307,  2.0719,  0.0000,  0.0000],
        [-1.1988, -1.0355, -1.2745, -1.7479,  0.3736,  0.0000],
        [-0.3380,  1.7570, -1.6608, -0.4785,  0.2950, -1.2821]])
```

### torch.einsum()
torch.einsum() 是 PyTorch 中一个非常强大的张量操作函数，它可以在一个表达式中组合和重组张量。einsum是对张量的一种高效的运算，其可以表达很多张量运算。einsum的核心思想是根据字符串表达式中的符号来计算张量之间的乘积，从而实现高效的多维数组计算。

einsum 的语法格式是：

`torch.einsum(equation, *operands)`

其中 equation 是一个字符串，用于指定张量之间的操作方式，operands 是一个包含要进行操作的张量的列表或元组。具体来说，equation 是一个由符号和轴标签组成的字符串，符号表示张量之间的操作方式，轴标签表示张量的轴的标签。例如，下面是一个简单的 einsum() 示例：

```python
import torch

a = torch.tensor([[1, 2], [3, 4]])
b = torch.tensor([[5, 6], [7, 8]])
c = torch.einsum('ij,jk->ik', a, b)

print(c)
```


在这个示例中，我们首先创建了两个 2x2 的张量 A 和 B，然后使用 einsum() 函数计算它们的矩阵乘积，并将结果存储在结果张量 c 中。在 einsum() 的表达式中，i 和 j 来自第一个操作数 a 的两个轴，j 和 k 来自第二个操作数 b 的两个轴，->ik 则表示将两个操作数的轴乘积沿第二个轴求和，即计算矩阵乘积的结果。

einsum() 函数非常灵活，可以用于执行各种各样的操作，例如：

* 张量加法和减法
* 矩阵乘法和矩阵转置
* 张量压缩和张量展开
* 张量缩并和张量分裂

总之，einsum() 函数是一个非常强大和灵活的张量操作函数，它能够帮助您实现各种各样的张量操作，加速您的深度学习代码。

### torch.detach()
经过detach()返回的张量不会方向传播计算梯度

********************************************************************************************************************************

## numpy
### np.append()
函数原型：
```python
def append(arr, values, axis=None):
```
**参数：**
* **arr**:需要被添加values的数组
* **values**:添加到数组arr中的值（array_like，类数组）
* **axis**:可选参数，如果axis没有给出，那么arr，values都将先展平成一维数组。注：如果axis被指定了，那么arr和values需要同为一维数组或者有相同的shape，否则报错：ValueError: arrays must have same number of dimensions

示例：[https://blog.csdn.net/weixin_42216109/article/details/93889047](https://blog.csdn.net/weixin_42216109/article/details/93889047)

### np.reshape()
改变nparray的维度大小

-1表示我不关心这个维度的大小，reshape(-1, 1)代表一列n行

示例：[https://blog.csdn.net/qq_43511299/article/details/117259662](https://blog.csdn.net/qq_43511299/article/details/117259662)

### np.empty()
通过使用np.empty(0)可以创建一个空的ndarray

### np.mean()、np.std()
计算ndarray的平均值与标准差

若未指定axis，那么是基于所有数据进行计算

********************************************************************************************************************************


## pandas
### dataframe.values
这个属性将能得到一个ndarray，将dataframe转为ndarray使用该属性将十分简单